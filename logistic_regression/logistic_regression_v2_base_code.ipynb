{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_LulNCC8z96"
   },
   "source": [
    "**D1AED: Análise Estatística para Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof: Samuel Martins <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#0C509E' style='font-size: 40px;'>Logistic Regression - v2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dummy dataset that pesents if customers have purchased a given product or not.<br/>\n",
    "\n",
    "**Dataset:** https://www.kaggle.com/rakeshrau/social-network-ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Extracting the independent and dependent variables\n",
    "For visualization purposes, we will consider only **two independent variables** (_Age_ and _EstimatedSalary_) for training the logistic regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyhQaTwP9RzG"
   },
   "source": [
    "## 3. Splitting the dataset into Training Set and Test Set\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "**PS:** Use _stratified_ split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Checking training and test set sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the samples' indices for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = X_train.index\n",
    "test_indices = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalizando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StandardScaler**: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descobre os parâmetros da normalização (fit) e já transforma/normaliza o conjunto de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalente a: np.sqrt(var_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma/normaliza o conjunto de teste baseado no \"normalizador\" aprendido a partir do conjunto de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZijQwFMQ9itx"
   },
   "source": [
    "## 5. Training a Logistic Regression Model\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learned Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the parameters learned for our **logistic regression model**, from the training set used, were:\n",
    "\n",
    "$\\theta^T = [\\theta_0, \\theta_1, \\theta_2] = [-0.995, 1.96, 1.13]$\n",
    "\n",
    "<span style=\"font-size: 20pt\">\n",
    "$\n",
    "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^{T}*x}} = \\frac{1}{1 + e^{-(-0.995 + 1.96 * x_1 + 1.13 * x_2)}}\n",
    "$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Decision boundary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering two dependent variables, the _decision boundary_ is a vertical plane:\n",
    "\n",
    "<span style='font-size: 20pt'>\n",
    "$\\theta_0 + \\theta_1 * x_1 + \\theta_2 * x_2 = 0$\n",
    "\n",
    "$\\theta_1 * x_1 + \\theta_2 * x_2 = -\\theta_0$\n",
    "    \n",
    "$x_2 = - (\\theta_0 + \\theta_1 * x_1) / \\theta_2$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = classifier.intercept_[0]\n",
    "theta_1 = classifier.coef_[0, 0]\n",
    "theta_2 = classifier.coef_[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_decision_line = np.array([X_train[:,0].min(), X_train[:,0].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_decision_line = -(theta_0 + (theta_1 * x1_decision_line)) / theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Putting it all together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = classifier.predict_proba(X_train)[:,1].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[train_indices, ['Age', 'EstimatedSalary', 'Purchased']].copy()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Normalized Age'] = X_train[:,0]\n",
    "df_train['Normalized Salary'] = X_train[:,1]\n",
    "df_train['Estimated Prob'] = classifier.predict_proba(X_train)[:,1].round(2)\n",
    "\n",
    "df_train['Purchased'].replace(0, 'No', inplace=True)\n",
    "df_train['Purchased'].replace(1, 'Yes', inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive plot by Plotly\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(df_train, x='Normalized Age', y='Normalized Salary', color='Purchased', hover_data=['Age', 'EstimatedSalary', 'Estimated Prob'], color_discrete_sequence=px.colors.qualitative.T10)\n",
    "fig.add_trace(go.Scatter(x=x1_decision_line, y=x2_decision_line, mode='lines', name='Decision Boundary'))\n",
    "\n",
    "fig.update_layout(title='Training set and Decision Boundary',\n",
    "                  xaxis_title='Normalized Age', yaxis_title='Normalized Salary', width=700, height=600)\n",
    "fig.update_xaxes(range=[X_train.min() - 0.5, X_train.max() + 0.5])\n",
    "fig.update_yaxes(range=[X_train.min() - 0.5, X_train.max() + 0.5])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same static plot by SeaBorn\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "sns.scatterplot(data=df_train, x='Normalized Age', y='Normalized Salary', hue='Purchased')\n",
    "sns.lineplot(x=x1_decision_line, y=x2_decision_line, color='lightseagreen')\n",
    "\n",
    "lim = df_train[['Normalized Age', 'Normalized Salary']].min().min() - 0.5, df_train[['Normalized Age', 'Normalized Salary']].max().max() + 0.5\n",
    "plt.xlim(lim)\n",
    "plt.ylim(lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Learned model (sigmoid)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sig = np.arange(X_train[:,0].min() - 0.25, X_train[:,0].max() + 0.25, step=0.1)\n",
    "y_sig = np.arange(X_train[:,1].min() - 0.25, X_train[:,1].max() + 0.25, step=0.1)\n",
    "xv, yv = np.meshgrid(x_sig, y_sig)  # combinação dos x's e y's\n",
    "z_sig = classifier.predict_proba(np.array([xv.ravel(), yv.ravel()]).T)[:,1].reshape(xv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plane at the 50% Probability%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_plane = [X_train[:,0].min(), X_train[:,0].max()]\n",
    "x2_plane = [X_train[:,1].min(), X_train[:,1].max()]\n",
    "z_plane = [[0.5, 0.5], [0.5, 0.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Decision Boundary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering two dependent variables, the _decision boundary_ is a vertical plane:\n",
    "\n",
    "<span style='font-size: 20pt'>\n",
    "$\\theta_0 + \\theta_1 * x_1 + \\theta_2 * x_2 = 0$\n",
    "\n",
    "$\\theta_1 * x_1 + \\theta_2 * x_2 = -\\theta_0$\n",
    "    \n",
    "$x_2 = - (\\theta_0 + \\theta_1 * x_1) / \\theta_2$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = classifier.intercept_[0]\n",
    "theta_1 = classifier.coef_[0, 0]\n",
    "theta_2 = classifier.coef_[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_decision = np.arange(X_train[:,0].min(), X_train[:,0].max(), step=0.1)\n",
    "z_decision = np.linspace(0, 1.0, x1_decision.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_decision, Z_decision = np.meshgrid(x1_decision, z_decision)\n",
    "X2_decision = -(theta_0 + (theta_1 * X1_decision)) / theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Putting it all together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/53116010\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "                    go.Surface(x=X1_decision, y=X2_decision, z=Z_decision, colorscale=[[0, 'paleturquoise'], [1.0, 'paleturquoise']]),\n",
    "                    go.Surface(x=x1_plane, y=x2_plane, z=z_plane, colorscale=[[0, 'gray'], [1.0, 'gray']]),\n",
    "                    go.Scatter3d(x=X_train[:,0], y=X_train[:,1], z=y_train, mode='markers',\n",
    "                                marker=dict(size=6, color=y_train, colorscale=[[0, '#4C78A8'], [1, '#F58518']], opacity=0.8)),\n",
    "                    go.Surface(x=x_sig, y=y_sig, z=z_sig),\n",
    "            ])\n",
    "\n",
    "fig.update_layout(title='Training set and Decision Boundary',\n",
    "                  scene=dict(xaxis_title='Normalized Age', yaxis_title='Normalized Salary', zaxis_title='Estimated Prob'), width=1200, height=1000)\n",
    "fig.update_xaxes(range=[X_train.min() - 0.5, X_train.max() + 0.5])\n",
    "fig.update_yaxes(range=[X_train.min() - 0.5, X_train.max() + 0.5])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wa2T1Lq89o5H"
   },
   "source": [
    "## 7. Classification / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zSoMZ-P9v8t"
   },
   "source": [
    "## 8. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "sns.scatterplot(x=X_test[:,0], y=X_test[:,1], hue=y_test)\n",
    "sns.lineplot(x=x1_decision_line, y=x2_decision_line, color='lightseagreen')\n",
    "\n",
    "lim = X_test.min() - 0.5, X_test.max() + 0.5\n",
    "plt.xlabel('Normalized Age')\n",
    "plt.ylabel('Normalized Salary')\n",
    "plt.xlim(lim)\n",
    "plt.ylim(lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP1VVwrQU8S68bmX5lftYWC",
   "name": "Simple Linear Regression",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
